// Copyright 2017 Google Inc.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v1.3.0 with parameter "target=ts"
// @generated from file google/cloud/ml/v1beta1/job_service.proto (package google.cloud.ml.v1beta1, syntax proto3)
/* eslint-disable */
// @ts-nocheck

import type { BinaryReadOptions, FieldList, JsonReadOptions, JsonValue, PartialMessage, PlainMessage } from "@bufbuild/protobuf";
import { Message, proto3, protoInt64, Timestamp } from "@bufbuild/protobuf";

/**
 * Represents input parameters for a training job.
 *
 * @generated from message google.cloud.ml.v1beta1.TrainingInput
 */
export class TrainingInput extends Message<TrainingInput> {
  /**
   * Required. Specifies the machine types, the number of replicas for workers
   * and parameter servers.
   *
   * @generated from field: google.cloud.ml.v1beta1.TrainingInput.ScaleTier scale_tier = 1;
   */
  scaleTier = TrainingInput_ScaleTier.BASIC;

  /**
   * Optional. Specifies the type of virtual machine to use for your training
   * job's master worker.
   *
   * The following types are supported:
   *
   * <dl>
   *   <dt>standard</dt>
   *   <dd>
   *   A basic machine configuration suitable for training simple models with
   *   small to moderate datasets.
   *   </dd>
   *   <dt>large_model</dt>
   *   <dd>
   *   A machine with a lot of memory, specially suited for parameter servers
   *   when your model is large (having many hidden layers or layers with very
   *   large numbers of nodes).
   *   </dd>
   *   <dt>complex_model_s</dt>
   *   <dd>
   *   A machine suitable for the master and workers of the cluster when your
   *   model requires more computation than the standard machine can handle
   *   satisfactorily.
   *   </dd>
   *   <dt>complex_model_m</dt>
   *   <dd>
   *   A machine with roughly twice the number of cores and roughly double the
   *   memory of <code suppresswarning="true">complex_model_s</code>.
   *   </dd>
   *   <dt>complex_model_l</dt>
   *   <dd>
   *   A machine with roughly twice the number of cores and roughly double the
   *   memory of <code suppresswarning="true">complex_model_m</code>.
   *   </dd>
   *   <dt>standard_gpu</dt>
   *   <dd>
   *   A machine equivalent to <code suppresswarning="true">standard</code> that
   *   also includes a
   *   <a href="ml/docs/how-tos/using-gpus">
   *   GPU that you can use in your trainer</a>.
   *   </dd>
   *   <dt>complex_model_m_gpu</dt>
   *   <dd>
   *   A machine equivalent to
   *   <code suppresswarning="true">coplex_model_m</code> that also includes
   *   four GPUs.
   *   </dd>
   * </dl>
   *
   * You must set this value when `scaleTier` is set to `CUSTOM`.
   *
   * @generated from field: string master_type = 2;
   */
  masterType = "";

  /**
   * Optional. Specifies the type of virtual machine to use for your training
   * job's worker nodes.
   *
   * The supported values are the same as those described in the entry for
   * `masterType`.
   *
   * This value must be present when `scaleTier` is set to `CUSTOM` and
   * `workerCount` is greater than zero.
   *
   * @generated from field: string worker_type = 3;
   */
  workerType = "";

  /**
   * Optional. Specifies the type of virtual machine to use for your training
   * job's parameter server.
   *
   * The supported values are the same as those described in the entry for
   * `master_type`.
   *
   * This value must be present when `scaleTier` is set to `CUSTOM` and
   * `parameter_server_count` is greater than zero.
   *
   * @generated from field: string parameter_server_type = 4;
   */
  parameterServerType = "";

  /**
   * Optional. The number of worker replicas to use for the training job. Each
   * replica in the cluster will be of the type specified in `worker_type`.
   *
   * This value can only be used when `scale_tier` is set to `CUSTOM`. If you
   * set this value, you must also set `worker_type`.
   *
   * @generated from field: int64 worker_count = 5;
   */
  workerCount = protoInt64.zero;

  /**
   * Optional. The number of parameter server replicas to use for the training
   * job. Each replica in the cluster will be of the type specified in
   * `parameter_server_type`.
   *
   * This value can only be used when `scale_tier` is set to `CUSTOM`.If you
   * set this value, you must also set `parameter_server_type`.
   *
   * @generated from field: int64 parameter_server_count = 6;
   */
  parameterServerCount = protoInt64.zero;

  /**
   * Required. The Google Cloud Storage location of the packages with
   * the training program and any additional dependencies.
   *
   * @generated from field: repeated string package_uris = 7;
   */
  packageUris: string[] = [];

  /**
   * Required. The Python module name to run after installing the packages.
   *
   * @generated from field: string python_module = 8;
   */
  pythonModule = "";

  /**
   * Optional. Command line arguments to pass to the program.
   *
   * @generated from field: repeated string args = 10;
   */
  args: string[] = [];

  /**
   * Optional. The set of Hyperparameters to tune.
   *
   * @generated from field: google.cloud.ml.v1beta1.HyperparameterSpec hyperparameters = 12;
   */
  hyperparameters?: HyperparameterSpec;

  /**
   * Required. The Google Compute Engine region to run the training job in.
   *
   * @generated from field: string region = 14;
   */
  region = "";

  /**
   * Optional. A Google Cloud Storage path in which to store training outputs
   * and other data needed for training. This path is passed to your TensorFlow
   * program as the 'job_dir' command-line argument. The benefit of specifying
   * this field is that Cloud ML validates the path for use in training.
   *
   * @generated from field: string job_dir = 16;
   */
  jobDir = "";

  /**
   * Optional. The Google Cloud ML runtime version to use for training.  If not
   * set, Google Cloud ML will choose the latest stable version.
   *
   * @generated from field: string runtime_version = 15;
   */
  runtimeVersion = "";

  constructor(data?: PartialMessage<TrainingInput>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.ml.v1beta1.TrainingInput";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "scale_tier", kind: "enum", T: proto3.getEnumType(TrainingInput_ScaleTier) },
    { no: 2, name: "master_type", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "worker_type", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 4, name: "parameter_server_type", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 5, name: "worker_count", kind: "scalar", T: 3 /* ScalarType.INT64 */ },
    { no: 6, name: "parameter_server_count", kind: "scalar", T: 3 /* ScalarType.INT64 */ },
    { no: 7, name: "package_uris", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
    { no: 8, name: "python_module", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 10, name: "args", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
    { no: 12, name: "hyperparameters", kind: "message", T: HyperparameterSpec },
    { no: 14, name: "region", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 16, name: "job_dir", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 15, name: "runtime_version", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TrainingInput {
    return new TrainingInput().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TrainingInput {
    return new TrainingInput().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TrainingInput {
    return new TrainingInput().fromJsonString(jsonString, options);
  }

  static equals(a: TrainingInput | PlainMessage<TrainingInput> | undefined, b: TrainingInput | PlainMessage<TrainingInput> | undefined): boolean {
    return proto3.util.equals(TrainingInput, a, b);
  }
}

/**
 * A scale tier is an abstract representation of the resources Cloud ML
 * will allocate to a training job. When selecting a scale tier for your
 * training job, you should consider the size of your training dataset and
 * the complexity of your model. As the tiers increase, virtual machines are
 * added to handle your job, and the individual machines in the cluster
 * generally have more memory and greater processing power than they do at
 * lower tiers. The number of training units charged per hour of processing
 * increases as tiers get more advanced. Refer to the
 * [pricing guide](/ml/pricing) for more details. Note that in addition to
 * incurring costs, your use of training resources is constrained by the
 * [quota policy](/ml/quota).
 *
 * @generated from enum google.cloud.ml.v1beta1.TrainingInput.ScaleTier
 */
export enum TrainingInput_ScaleTier {
  /**
   * A single worker instance. This tier is suitable for learning how to use
   * Cloud ML, and for experimenting with new models using small datasets.
   *
   * @generated from enum value: BASIC = 0;
   */
  BASIC = 0,

  /**
   * Many workers and a few parameter servers.
   *
   * @generated from enum value: STANDARD_1 = 1;
   */
  STANDARD_1 = 1,

  /**
   * A large number of workers with many parameter servers.
   *
   * @generated from enum value: PREMIUM_1 = 3;
   */
  PREMIUM_1 = 3,

  /**
   * A single worker instance [with a GPU](ml/docs/how-tos/using-gpus).
   *
   * @generated from enum value: BASIC_GPU = 6;
   */
  BASIC_GPU = 6,

  /**
   * The CUSTOM tier is not a set tier, but rather enables you to use your
   * own cluster specification. When you use this tier, set values to
   * configure your processing cluster according to these guidelines:
   *
   * *   You _must_ set `TrainingInput.masterType` to specify the type
   *     of machine to use for your master node. This is the only required
   *     setting.
   *
   * *   You _may_ set `TrainingInput.workerCount` to specify the number of
   *     workers to use. If you specify one or more workers, you _must_ also
   *     set `TrainingInput.workerType` to specify the type of machine to use
   *     for your worker nodes.
   *
   * *   You _may_ set `TrainingInput.parameterServerCount` to specify the
   *     number of parameter servers to use. If you specify one or more
   *     parameter servers, you _must_ also set
   *     `TrainingInput.parameterServerType` to specify the type of machine to
   *     use for your parameter servers.
   *
   * Note that all of your workers must use the same machine type, which can
   * be different from your parameter server type and master type. Your
   * parameter servers must likewise use the same machine type, which can be
   * different from your worker type and master type.
   *
   * @generated from enum value: CUSTOM = 5;
   */
  CUSTOM = 5,
}
// Retrieve enum metadata with: proto3.getEnumType(TrainingInput_ScaleTier)
proto3.util.setEnumType(TrainingInput_ScaleTier, "google.cloud.ml.v1beta1.TrainingInput.ScaleTier", [
  { no: 0, name: "BASIC" },
  { no: 1, name: "STANDARD_1" },
  { no: 3, name: "PREMIUM_1" },
  { no: 6, name: "BASIC_GPU" },
  { no: 5, name: "CUSTOM" },
]);

/**
 * Represents a set of hyperparameters to optimize.
 *
 * @generated from message google.cloud.ml.v1beta1.HyperparameterSpec
 */
export class HyperparameterSpec extends Message<HyperparameterSpec> {
  /**
   * Required. The type of goal to use for tuning. Available types are
   * `MAXIMIZE` and `MINIMIZE`.
   *
   * Defaults to `MAXIMIZE`.
   *
   * @generated from field: google.cloud.ml.v1beta1.HyperparameterSpec.GoalType goal = 1;
   */
  goal = HyperparameterSpec_GoalType.GOAL_TYPE_UNSPECIFIED;

  /**
   * Required. The set of parameters to tune.
   *
   * @generated from field: repeated google.cloud.ml.v1beta1.ParameterSpec params = 2;
   */
  params: ParameterSpec[] = [];

  /**
   * Optional. How many training trials should be attempted to optimize
   * the specified hyperparameters.
   *
   * Defaults to one.
   *
   * @generated from field: int32 max_trials = 3;
   */
  maxTrials = 0;

  /**
   * Optional. The number of training trials to run concurrently.
   * You can reduce the time it takes to perform hyperparameter tuning by adding
   * trials in parallel. However, each trail only benefits from the information
   * gained in completed trials. That means that a trial does not get access to
   * the results of trials running at the same time, which could reduce the
   * quality of the overall optimization.
   *
   * Each trial will use the same scale tier and machine types.
   *
   * Defaults to one.
   *
   * @generated from field: int32 max_parallel_trials = 4;
   */
  maxParallelTrials = 0;

  /**
   * Optional. The Tensorflow summary tag name to use for optimizing trials. For
   * current versions of Tensorflow, this tag name should exactly match what is
   * shown in Tensorboard, including all scopes.  For versions of Tensorflow
   * prior to 0.12, this should be only the tag passed to tf.Summary.
   * By default, "training/hptuning/metric" will be used.
   *
   * @generated from field: string hyperparameter_metric_tag = 5;
   */
  hyperparameterMetricTag = "";

  constructor(data?: PartialMessage<HyperparameterSpec>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.ml.v1beta1.HyperparameterSpec";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "goal", kind: "enum", T: proto3.getEnumType(HyperparameterSpec_GoalType) },
    { no: 2, name: "params", kind: "message", T: ParameterSpec, repeated: true },
    { no: 3, name: "max_trials", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 4, name: "max_parallel_trials", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 5, name: "hyperparameter_metric_tag", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): HyperparameterSpec {
    return new HyperparameterSpec().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): HyperparameterSpec {
    return new HyperparameterSpec().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): HyperparameterSpec {
    return new HyperparameterSpec().fromJsonString(jsonString, options);
  }

  static equals(a: HyperparameterSpec | PlainMessage<HyperparameterSpec> | undefined, b: HyperparameterSpec | PlainMessage<HyperparameterSpec> | undefined): boolean {
    return proto3.util.equals(HyperparameterSpec, a, b);
  }
}

/**
 * The available types of optimization goals.
 *
 * @generated from enum google.cloud.ml.v1beta1.HyperparameterSpec.GoalType
 */
export enum HyperparameterSpec_GoalType {
  /**
   * Goal Type will default to maximize.
   *
   * @generated from enum value: GOAL_TYPE_UNSPECIFIED = 0;
   */
  GOAL_TYPE_UNSPECIFIED = 0,

  /**
   * Maximize the goal metric.
   *
   * @generated from enum value: MAXIMIZE = 1;
   */
  MAXIMIZE = 1,

  /**
   * Minimize the goal metric.
   *
   * @generated from enum value: MINIMIZE = 2;
   */
  MINIMIZE = 2,
}
// Retrieve enum metadata with: proto3.getEnumType(HyperparameterSpec_GoalType)
proto3.util.setEnumType(HyperparameterSpec_GoalType, "google.cloud.ml.v1beta1.HyperparameterSpec.GoalType", [
  { no: 0, name: "GOAL_TYPE_UNSPECIFIED" },
  { no: 1, name: "MAXIMIZE" },
  { no: 2, name: "MINIMIZE" },
]);

/**
 * Represents a single hyperparameter to optimize.
 *
 * @generated from message google.cloud.ml.v1beta1.ParameterSpec
 */
export class ParameterSpec extends Message<ParameterSpec> {
  /**
   * Required. The parameter name must be unique amongst all ParameterConfigs in
   * a HyperparameterSpec message. E.g., "learning_rate".
   *
   * @generated from field: string parameter_name = 1;
   */
  parameterName = "";

  /**
   * Required. The type of the parameter.
   *
   * @generated from field: google.cloud.ml.v1beta1.ParameterSpec.ParameterType type = 4;
   */
  type = ParameterSpec_ParameterType.PARAMETER_TYPE_UNSPECIFIED;

  /**
   * Required if type is `DOUBLE` or `INTEGER`. This field
   * should be unset if type is `CATEGORICAL`. This value should be integers if
   * type is INTEGER.
   *
   * @generated from field: double min_value = 2;
   */
  minValue = 0;

  /**
   * Required if typeis `DOUBLE` or `INTEGER`. This field
   * should be unset if type is `CATEGORICAL`. This value should be integers if
   * type is `INTEGER`.
   *
   * @generated from field: double max_value = 3;
   */
  maxValue = 0;

  /**
   * Required if type is `CATEGORICAL`. The list of possible categories.
   *
   * @generated from field: repeated string categorical_values = 5;
   */
  categoricalValues: string[] = [];

  /**
   * Required if type is `DISCRETE`.
   * A list of feasible points.
   * The list should be in strictly increasing order. For instance, this
   * parameter might have possible settings of 1.5, 2.5, and 4.0. This list
   * should not contain more than 1,000 values.
   *
   * @generated from field: repeated double discrete_values = 6;
   */
  discreteValues: number[] = [];

  /**
   * Optional. How the parameter should be scaled to the hypercube.
   * Leave unset for categorical parameters.
   * Some kind of scaling is strongly recommended for real or integral
   * parameters (e.g., `UNIT_LINEAR_SCALE`).
   *
   * @generated from field: google.cloud.ml.v1beta1.ParameterSpec.ScaleType scale_type = 7;
   */
  scaleType = ParameterSpec_ScaleType.NONE;

  constructor(data?: PartialMessage<ParameterSpec>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.ml.v1beta1.ParameterSpec";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "parameter_name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 4, name: "type", kind: "enum", T: proto3.getEnumType(ParameterSpec_ParameterType) },
    { no: 2, name: "min_value", kind: "scalar", T: 1 /* ScalarType.DOUBLE */ },
    { no: 3, name: "max_value", kind: "scalar", T: 1 /* ScalarType.DOUBLE */ },
    { no: 5, name: "categorical_values", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
    { no: 6, name: "discrete_values", kind: "scalar", T: 1 /* ScalarType.DOUBLE */, repeated: true },
    { no: 7, name: "scale_type", kind: "enum", T: proto3.getEnumType(ParameterSpec_ScaleType) },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ParameterSpec {
    return new ParameterSpec().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ParameterSpec {
    return new ParameterSpec().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ParameterSpec {
    return new ParameterSpec().fromJsonString(jsonString, options);
  }

  static equals(a: ParameterSpec | PlainMessage<ParameterSpec> | undefined, b: ParameterSpec | PlainMessage<ParameterSpec> | undefined): boolean {
    return proto3.util.equals(ParameterSpec, a, b);
  }
}

/**
 * The type of the parameter.
 *
 * @generated from enum google.cloud.ml.v1beta1.ParameterSpec.ParameterType
 */
export enum ParameterSpec_ParameterType {
  /**
   * You must specify a valid type. Using this unspecified type will result in
   * an error.
   *
   * @generated from enum value: PARAMETER_TYPE_UNSPECIFIED = 0;
   */
  PARAMETER_TYPE_UNSPECIFIED = 0,

  /**
   * Type for real-valued parameters.
   *
   * @generated from enum value: DOUBLE = 1;
   */
  DOUBLE = 1,

  /**
   * Type for integral parameters.
   *
   * @generated from enum value: INTEGER = 2;
   */
  INTEGER = 2,

  /**
   * The parameter is categorical, with a value chosen from the categories
   * field.
   *
   * @generated from enum value: CATEGORICAL = 3;
   */
  CATEGORICAL = 3,

  /**
   * The parameter is real valued, with a fixed set of feasible points. If
   * `type==DISCRETE`, feasible_points must be provided, and
   * {`min_value`, `max_value`} will be ignored.
   *
   * @generated from enum value: DISCRETE = 4;
   */
  DISCRETE = 4,
}
// Retrieve enum metadata with: proto3.getEnumType(ParameterSpec_ParameterType)
proto3.util.setEnumType(ParameterSpec_ParameterType, "google.cloud.ml.v1beta1.ParameterSpec.ParameterType", [
  { no: 0, name: "PARAMETER_TYPE_UNSPECIFIED" },
  { no: 1, name: "DOUBLE" },
  { no: 2, name: "INTEGER" },
  { no: 3, name: "CATEGORICAL" },
  { no: 4, name: "DISCRETE" },
]);

/**
 * The type of scaling that should be applied to this parameter.
 *
 * @generated from enum google.cloud.ml.v1beta1.ParameterSpec.ScaleType
 */
export enum ParameterSpec_ScaleType {
  /**
   * By default, no scaling is applied.
   *
   * @generated from enum value: NONE = 0;
   */
  NONE = 0,

  /**
   * Scales the feasible space to (0, 1) linearly.
   *
   * @generated from enum value: UNIT_LINEAR_SCALE = 1;
   */
  UNIT_LINEAR_SCALE = 1,

  /**
   * Scales the feasible space logarithmically to (0, 1). The entire feasible
   * space must be strictly positive.
   *
   * @generated from enum value: UNIT_LOG_SCALE = 2;
   */
  UNIT_LOG_SCALE = 2,

  /**
   * Scales the feasible space "reverse" logarithmically to (0, 1). The result
   * is that values close to the top of the feasible space are spread out more
   * than points near the bottom. The entire feasible space must be strictly
   * positive.
   *
   * @generated from enum value: UNIT_REVERSE_LOG_SCALE = 3;
   */
  UNIT_REVERSE_LOG_SCALE = 3,
}
// Retrieve enum metadata with: proto3.getEnumType(ParameterSpec_ScaleType)
proto3.util.setEnumType(ParameterSpec_ScaleType, "google.cloud.ml.v1beta1.ParameterSpec.ScaleType", [
  { no: 0, name: "NONE" },
  { no: 1, name: "UNIT_LINEAR_SCALE" },
  { no: 2, name: "UNIT_LOG_SCALE" },
  { no: 3, name: "UNIT_REVERSE_LOG_SCALE" },
]);

/**
 * Represents the result of a single hyperparameter tuning trial from a
 * training job. The TrainingOutput object that is returned on successful
 * completion of a training job with hyperparameter tuning includes a list
 * of HyperparameterOutput objects, one for each successful trial.
 *
 * @generated from message google.cloud.ml.v1beta1.HyperparameterOutput
 */
export class HyperparameterOutput extends Message<HyperparameterOutput> {
  /**
   * The trial id for these results.
   *
   * @generated from field: string trial_id = 1;
   */
  trialId = "";

  /**
   * The hyperparameters given to this trial.
   *
   * @generated from field: map<string, string> hyperparameters = 2;
   */
  hyperparameters: { [key: string]: string } = {};

  /**
   * The final objective metric seen for this trial.
   *
   * @generated from field: google.cloud.ml.v1beta1.HyperparameterOutput.HyperparameterMetric final_metric = 3;
   */
  finalMetric?: HyperparameterOutput_HyperparameterMetric;

  /**
   * All recorded object metrics for this trial.
   *
   * @generated from field: repeated google.cloud.ml.v1beta1.HyperparameterOutput.HyperparameterMetric all_metrics = 4;
   */
  allMetrics: HyperparameterOutput_HyperparameterMetric[] = [];

  constructor(data?: PartialMessage<HyperparameterOutput>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.ml.v1beta1.HyperparameterOutput";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "trial_id", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "hyperparameters", kind: "map", K: 9 /* ScalarType.STRING */, V: {kind: "scalar", T: 9 /* ScalarType.STRING */} },
    { no: 3, name: "final_metric", kind: "message", T: HyperparameterOutput_HyperparameterMetric },
    { no: 4, name: "all_metrics", kind: "message", T: HyperparameterOutput_HyperparameterMetric, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): HyperparameterOutput {
    return new HyperparameterOutput().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): HyperparameterOutput {
    return new HyperparameterOutput().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): HyperparameterOutput {
    return new HyperparameterOutput().fromJsonString(jsonString, options);
  }

  static equals(a: HyperparameterOutput | PlainMessage<HyperparameterOutput> | undefined, b: HyperparameterOutput | PlainMessage<HyperparameterOutput> | undefined): boolean {
    return proto3.util.equals(HyperparameterOutput, a, b);
  }
}

/**
 * An observed value of a metric.
 *
 * @generated from message google.cloud.ml.v1beta1.HyperparameterOutput.HyperparameterMetric
 */
export class HyperparameterOutput_HyperparameterMetric extends Message<HyperparameterOutput_HyperparameterMetric> {
  /**
   * The global training step for this metric.
   *
   * @generated from field: int64 training_step = 1;
   */
  trainingStep = protoInt64.zero;

  /**
   * The objective value at this training step.
   *
   * @generated from field: double objective_value = 2;
   */
  objectiveValue = 0;

  constructor(data?: PartialMessage<HyperparameterOutput_HyperparameterMetric>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.ml.v1beta1.HyperparameterOutput.HyperparameterMetric";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "training_step", kind: "scalar", T: 3 /* ScalarType.INT64 */ },
    { no: 2, name: "objective_value", kind: "scalar", T: 1 /* ScalarType.DOUBLE */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): HyperparameterOutput_HyperparameterMetric {
    return new HyperparameterOutput_HyperparameterMetric().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): HyperparameterOutput_HyperparameterMetric {
    return new HyperparameterOutput_HyperparameterMetric().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): HyperparameterOutput_HyperparameterMetric {
    return new HyperparameterOutput_HyperparameterMetric().fromJsonString(jsonString, options);
  }

  static equals(a: HyperparameterOutput_HyperparameterMetric | PlainMessage<HyperparameterOutput_HyperparameterMetric> | undefined, b: HyperparameterOutput_HyperparameterMetric | PlainMessage<HyperparameterOutput_HyperparameterMetric> | undefined): boolean {
    return proto3.util.equals(HyperparameterOutput_HyperparameterMetric, a, b);
  }
}

/**
 * Represents results of a training job. Output only.
 *
 * @generated from message google.cloud.ml.v1beta1.TrainingOutput
 */
export class TrainingOutput extends Message<TrainingOutput> {
  /**
   * The number of hyperparameter tuning trials that completed successfully.
   * Only set for hyperparameter tuning jobs.
   *
   * @generated from field: int64 completed_trial_count = 1;
   */
  completedTrialCount = protoInt64.zero;

  /**
   * Results for individual Hyperparameter trials.
   * Only set for hyperparameter tuning jobs.
   *
   * @generated from field: repeated google.cloud.ml.v1beta1.HyperparameterOutput trials = 2;
   */
  trials: HyperparameterOutput[] = [];

  /**
   * The amount of ML units consumed by the job.
   *
   * @generated from field: double consumed_ml_units = 3;
   */
  consumedMlUnits = 0;

  /**
   * Whether this job is a hyperparameter tuning job.
   *
   * @generated from field: bool is_hyperparameter_tuning_job = 4;
   */
  isHyperparameterTuningJob = false;

  constructor(data?: PartialMessage<TrainingOutput>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.ml.v1beta1.TrainingOutput";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "completed_trial_count", kind: "scalar", T: 3 /* ScalarType.INT64 */ },
    { no: 2, name: "trials", kind: "message", T: HyperparameterOutput, repeated: true },
    { no: 3, name: "consumed_ml_units", kind: "scalar", T: 1 /* ScalarType.DOUBLE */ },
    { no: 4, name: "is_hyperparameter_tuning_job", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): TrainingOutput {
    return new TrainingOutput().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): TrainingOutput {
    return new TrainingOutput().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): TrainingOutput {
    return new TrainingOutput().fromJsonString(jsonString, options);
  }

  static equals(a: TrainingOutput | PlainMessage<TrainingOutput> | undefined, b: TrainingOutput | PlainMessage<TrainingOutput> | undefined): boolean {
    return proto3.util.equals(TrainingOutput, a, b);
  }
}

/**
 * Represents input parameters for a prediction job.
 *
 * @generated from message google.cloud.ml.v1beta1.PredictionInput
 */
export class PredictionInput extends Message<PredictionInput> {
  /**
   * Required. The model or the version to use for prediction.
   *
   * @generated from oneof google.cloud.ml.v1beta1.PredictionInput.model_version
   */
  modelVersion: {
    /**
     * Use this field if you want to use the default version for the specified
     * model. The string must use the following format:
     *
     * `"projects/<var>[YOUR_PROJECT]</var>/models/<var>[YOUR_MODEL]</var>"`
     *
     * @generated from field: string model_name = 1;
     */
    value: string;
    case: "modelName";
  } | {
    /**
     * Use this field if you want to specify a version of the model to use. The
     * string is formatted the same way as `model_version`, with the addition
     * of the version information:
     *
     * `"projects/<var>[YOUR_PROJECT]</var>/models/<var>YOUR_MODEL/versions/<var>[YOUR_VERSION]</var>"`
     *
     * @generated from field: string version_name = 2;
     */
    value: string;
    case: "versionName";
  } | {
    /**
     * Use this field if you want to specify a Google Cloud Storage path for
     * the model to use.
     *
     * @generated from field: string uri = 9;
     */
    value: string;
    case: "uri";
  } | { case: undefined; value?: undefined } = { case: undefined };

  /**
   * Required. The format of the input data files.
   *
   * @generated from field: google.cloud.ml.v1beta1.PredictionInput.DataFormat data_format = 3;
   */
  dataFormat = PredictionInput_DataFormat.DATA_FORMAT_UNSPECIFIED;

  /**
   * Required. The Google Cloud Storage location of the input data files.
   * May contain wildcards.
   *
   * @generated from field: repeated string input_paths = 4;
   */
  inputPaths: string[] = [];

  /**
   * Required. The output Google Cloud Storage location.
   *
   * @generated from field: string output_path = 5;
   */
  outputPath = "";

  /**
   * Optional. The maximum number of workers to be used for parallel processing.
   * Defaults to 10 if not specified.
   *
   * @generated from field: int64 max_worker_count = 6;
   */
  maxWorkerCount = protoInt64.zero;

  /**
   * Required. The Google Compute Engine region to run the prediction job in.
   *
   * @generated from field: string region = 7;
   */
  region = "";

  /**
   * Optional. The Google Cloud ML runtime version to use for this batch
   * prediction. If not set, Google Cloud ML will pick the runtime version used
   * during the CreateVersion request for this model version, or choose the
   * latest stable version when model version information is not available
   * such as when the model is specified by uri.
   *
   * @generated from field: string runtime_version = 8;
   */
  runtimeVersion = "";

  constructor(data?: PartialMessage<PredictionInput>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.ml.v1beta1.PredictionInput";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "model_name", kind: "scalar", T: 9 /* ScalarType.STRING */, oneof: "model_version" },
    { no: 2, name: "version_name", kind: "scalar", T: 9 /* ScalarType.STRING */, oneof: "model_version" },
    { no: 9, name: "uri", kind: "scalar", T: 9 /* ScalarType.STRING */, oneof: "model_version" },
    { no: 3, name: "data_format", kind: "enum", T: proto3.getEnumType(PredictionInput_DataFormat) },
    { no: 4, name: "input_paths", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
    { no: 5, name: "output_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 6, name: "max_worker_count", kind: "scalar", T: 3 /* ScalarType.INT64 */ },
    { no: 7, name: "region", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 8, name: "runtime_version", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): PredictionInput {
    return new PredictionInput().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): PredictionInput {
    return new PredictionInput().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): PredictionInput {
    return new PredictionInput().fromJsonString(jsonString, options);
  }

  static equals(a: PredictionInput | PlainMessage<PredictionInput> | undefined, b: PredictionInput | PlainMessage<PredictionInput> | undefined): boolean {
    return proto3.util.equals(PredictionInput, a, b);
  }
}

/**
 * The format used to separate data instances in the source files.
 *
 * @generated from enum google.cloud.ml.v1beta1.PredictionInput.DataFormat
 */
export enum PredictionInput_DataFormat {
  /**
   * Unspecified format.
   *
   * @generated from enum value: DATA_FORMAT_UNSPECIFIED = 0;
   */
  DATA_FORMAT_UNSPECIFIED = 0,

  /**
   * The source file is a text file with instances separated by the
   * new-line character.
   *
   * @generated from enum value: TEXT = 1;
   */
  TEXT = 1,

  /**
   * The source file is a TFRecord file.
   *
   * @generated from enum value: TF_RECORD = 2;
   */
  TF_RECORD = 2,

  /**
   * The source file is a GZIP-compressed TFRecord file.
   *
   * @generated from enum value: TF_RECORD_GZIP = 3;
   */
  TF_RECORD_GZIP = 3,
}
// Retrieve enum metadata with: proto3.getEnumType(PredictionInput_DataFormat)
proto3.util.setEnumType(PredictionInput_DataFormat, "google.cloud.ml.v1beta1.PredictionInput.DataFormat", [
  { no: 0, name: "DATA_FORMAT_UNSPECIFIED" },
  { no: 1, name: "TEXT" },
  { no: 2, name: "TF_RECORD" },
  { no: 3, name: "TF_RECORD_GZIP" },
]);

/**
 * Represents results of a prediction job.
 *
 * @generated from message google.cloud.ml.v1beta1.PredictionOutput
 */
export class PredictionOutput extends Message<PredictionOutput> {
  /**
   * The output Google Cloud Storage location provided at the job creation time.
   *
   * @generated from field: string output_path = 1;
   */
  outputPath = "";

  /**
   * The number of generated predictions.
   *
   * @generated from field: int64 prediction_count = 2;
   */
  predictionCount = protoInt64.zero;

  /**
   * The number of data instances which resulted in errors.
   *
   * @generated from field: int64 error_count = 3;
   */
  errorCount = protoInt64.zero;

  /**
   * Node hours used by the batch prediction job.
   *
   * @generated from field: double node_hours = 4;
   */
  nodeHours = 0;

  constructor(data?: PartialMessage<PredictionOutput>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.ml.v1beta1.PredictionOutput";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "output_path", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "prediction_count", kind: "scalar", T: 3 /* ScalarType.INT64 */ },
    { no: 3, name: "error_count", kind: "scalar", T: 3 /* ScalarType.INT64 */ },
    { no: 4, name: "node_hours", kind: "scalar", T: 1 /* ScalarType.DOUBLE */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): PredictionOutput {
    return new PredictionOutput().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): PredictionOutput {
    return new PredictionOutput().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): PredictionOutput {
    return new PredictionOutput().fromJsonString(jsonString, options);
  }

  static equals(a: PredictionOutput | PlainMessage<PredictionOutput> | undefined, b: PredictionOutput | PlainMessage<PredictionOutput> | undefined): boolean {
    return proto3.util.equals(PredictionOutput, a, b);
  }
}

/**
 * Represents a training or prediction job.
 *
 * @generated from message google.cloud.ml.v1beta1.Job
 */
export class Job extends Message<Job> {
  /**
   * Required. The user-specified id of the job.
   *
   * @generated from field: string job_id = 1;
   */
  jobId = "";

  /**
   * Required. Parameters to create a job.
   *
   * @generated from oneof google.cloud.ml.v1beta1.Job.input
   */
  input: {
    /**
     * Input parameters to create a training job.
     *
     * @generated from field: google.cloud.ml.v1beta1.TrainingInput training_input = 2;
     */
    value: TrainingInput;
    case: "trainingInput";
  } | {
    /**
     * Input parameters to create a prediction job.
     *
     * @generated from field: google.cloud.ml.v1beta1.PredictionInput prediction_input = 3;
     */
    value: PredictionInput;
    case: "predictionInput";
  } | { case: undefined; value?: undefined } = { case: undefined };

  /**
   * Output only. When the job was created.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 4;
   */
  createTime?: Timestamp;

  /**
   * Output only. When the job processing was started.
   *
   * @generated from field: google.protobuf.Timestamp start_time = 5;
   */
  startTime?: Timestamp;

  /**
   * Output only. When the job processing was completed.
   *
   * @generated from field: google.protobuf.Timestamp end_time = 6;
   */
  endTime?: Timestamp;

  /**
   * Output only. The detailed state of a job.
   *
   * @generated from field: google.cloud.ml.v1beta1.Job.State state = 7;
   */
  state = Job_State.STATE_UNSPECIFIED;

  /**
   * Output only. The details of a failure or a cancellation.
   *
   * @generated from field: string error_message = 8;
   */
  errorMessage = "";

  /**
   * Output only. The current result of the job.
   *
   * @generated from oneof google.cloud.ml.v1beta1.Job.output
   */
  output: {
    /**
     * The current training job result.
     *
     * @generated from field: google.cloud.ml.v1beta1.TrainingOutput training_output = 9;
     */
    value: TrainingOutput;
    case: "trainingOutput";
  } | {
    /**
     * The current prediction job result.
     *
     * @generated from field: google.cloud.ml.v1beta1.PredictionOutput prediction_output = 10;
     */
    value: PredictionOutput;
    case: "predictionOutput";
  } | { case: undefined; value?: undefined } = { case: undefined };

  constructor(data?: PartialMessage<Job>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.ml.v1beta1.Job";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "job_id", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "training_input", kind: "message", T: TrainingInput, oneof: "input" },
    { no: 3, name: "prediction_input", kind: "message", T: PredictionInput, oneof: "input" },
    { no: 4, name: "create_time", kind: "message", T: Timestamp },
    { no: 5, name: "start_time", kind: "message", T: Timestamp },
    { no: 6, name: "end_time", kind: "message", T: Timestamp },
    { no: 7, name: "state", kind: "enum", T: proto3.getEnumType(Job_State) },
    { no: 8, name: "error_message", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 9, name: "training_output", kind: "message", T: TrainingOutput, oneof: "output" },
    { no: 10, name: "prediction_output", kind: "message", T: PredictionOutput, oneof: "output" },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): Job {
    return new Job().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): Job {
    return new Job().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): Job {
    return new Job().fromJsonString(jsonString, options);
  }

  static equals(a: Job | PlainMessage<Job> | undefined, b: Job | PlainMessage<Job> | undefined): boolean {
    return proto3.util.equals(Job, a, b);
  }
}

/**
 * Describes the job state.
 *
 * @generated from enum google.cloud.ml.v1beta1.Job.State
 */
export enum Job_State {
  /**
   * The job state is unspecified.
   *
   * @generated from enum value: STATE_UNSPECIFIED = 0;
   */
  STATE_UNSPECIFIED = 0,

  /**
   * The job has been just created and processing has not yet begun.
   *
   * @generated from enum value: QUEUED = 1;
   */
  QUEUED = 1,

  /**
   * The service is preparing to run the job.
   *
   * @generated from enum value: PREPARING = 2;
   */
  PREPARING = 2,

  /**
   * The job is in progress.
   *
   * @generated from enum value: RUNNING = 3;
   */
  RUNNING = 3,

  /**
   * The job completed successfully.
   *
   * @generated from enum value: SUCCEEDED = 4;
   */
  SUCCEEDED = 4,

  /**
   * The job failed.
   * `error_message` should contain the details of the failure.
   *
   * @generated from enum value: FAILED = 5;
   */
  FAILED = 5,

  /**
   * The job is being cancelled.
   * `error_message` should describe the reason for the cancellation.
   *
   * @generated from enum value: CANCELLING = 6;
   */
  CANCELLING = 6,

  /**
   * The job has been cancelled.
   * `error_message` should describe the reason for the cancellation.
   *
   * @generated from enum value: CANCELLED = 7;
   */
  CANCELLED = 7,
}
// Retrieve enum metadata with: proto3.getEnumType(Job_State)
proto3.util.setEnumType(Job_State, "google.cloud.ml.v1beta1.Job.State", [
  { no: 0, name: "STATE_UNSPECIFIED" },
  { no: 1, name: "QUEUED" },
  { no: 2, name: "PREPARING" },
  { no: 3, name: "RUNNING" },
  { no: 4, name: "SUCCEEDED" },
  { no: 5, name: "FAILED" },
  { no: 6, name: "CANCELLING" },
  { no: 7, name: "CANCELLED" },
]);

/**
 * Request message for the CreateJob method.
 *
 * @generated from message google.cloud.ml.v1beta1.CreateJobRequest
 */
export class CreateJobRequest extends Message<CreateJobRequest> {
  /**
   * Required. The project name.
   *
   * Authorization: requires `Editor` role on the specified project.
   *
   * @generated from field: string parent = 1;
   */
  parent = "";

  /**
   * Required. The job to create.
   *
   * @generated from field: google.cloud.ml.v1beta1.Job job = 2;
   */
  job?: Job;

  constructor(data?: PartialMessage<CreateJobRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.ml.v1beta1.CreateJobRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "parent", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "job", kind: "message", T: Job },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): CreateJobRequest {
    return new CreateJobRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): CreateJobRequest {
    return new CreateJobRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): CreateJobRequest {
    return new CreateJobRequest().fromJsonString(jsonString, options);
  }

  static equals(a: CreateJobRequest | PlainMessage<CreateJobRequest> | undefined, b: CreateJobRequest | PlainMessage<CreateJobRequest> | undefined): boolean {
    return proto3.util.equals(CreateJobRequest, a, b);
  }
}

/**
 * Request message for the ListJobs method.
 *
 * @generated from message google.cloud.ml.v1beta1.ListJobsRequest
 */
export class ListJobsRequest extends Message<ListJobsRequest> {
  /**
   * Required. The name of the project for which to list jobs.
   *
   * Authorization: requires `Viewer` role on the specified project.
   *
   * @generated from field: string parent = 1;
   */
  parent = "";

  /**
   * Optional. Specifies the subset of jobs to retrieve.
   *
   * @generated from field: string filter = 2;
   */
  filter = "";

  /**
   * Optional. A page token to request the next page of results.
   *
   * You get the token from the `next_page_token` field of the response from
   * the previous call.
   *
   * @generated from field: string page_token = 4;
   */
  pageToken = "";

  /**
   * Optional. The number of jobs to retrieve per "page" of results. If there
   * are more remaining results than this number, the response message will
   * contain a valid value in the `next_page_token` field.
   *
   * The default value is 20, and the maximum page size is 100.
   *
   * @generated from field: int32 page_size = 5;
   */
  pageSize = 0;

  constructor(data?: PartialMessage<ListJobsRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.ml.v1beta1.ListJobsRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "parent", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "filter", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 4, name: "page_token", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 5, name: "page_size", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ListJobsRequest {
    return new ListJobsRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ListJobsRequest {
    return new ListJobsRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ListJobsRequest {
    return new ListJobsRequest().fromJsonString(jsonString, options);
  }

  static equals(a: ListJobsRequest | PlainMessage<ListJobsRequest> | undefined, b: ListJobsRequest | PlainMessage<ListJobsRequest> | undefined): boolean {
    return proto3.util.equals(ListJobsRequest, a, b);
  }
}

/**
 * Response message for the ListJobs method.
 *
 * @generated from message google.cloud.ml.v1beta1.ListJobsResponse
 */
export class ListJobsResponse extends Message<ListJobsResponse> {
  /**
   * The list of jobs.
   *
   * @generated from field: repeated google.cloud.ml.v1beta1.Job jobs = 1;
   */
  jobs: Job[] = [];

  /**
   * Optional. Pass this token as the `page_token` field of the request for a
   * subsequent call.
   *
   * @generated from field: string next_page_token = 2;
   */
  nextPageToken = "";

  constructor(data?: PartialMessage<ListJobsResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.ml.v1beta1.ListJobsResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "jobs", kind: "message", T: Job, repeated: true },
    { no: 2, name: "next_page_token", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ListJobsResponse {
    return new ListJobsResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ListJobsResponse {
    return new ListJobsResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ListJobsResponse {
    return new ListJobsResponse().fromJsonString(jsonString, options);
  }

  static equals(a: ListJobsResponse | PlainMessage<ListJobsResponse> | undefined, b: ListJobsResponse | PlainMessage<ListJobsResponse> | undefined): boolean {
    return proto3.util.equals(ListJobsResponse, a, b);
  }
}

/**
 * Request message for the GetJob method.
 *
 * @generated from message google.cloud.ml.v1beta1.GetJobRequest
 */
export class GetJobRequest extends Message<GetJobRequest> {
  /**
   * Required. The name of the job to get the description of.
   *
   * Authorization: requires `Viewer` role on the parent project.
   *
   * @generated from field: string name = 1;
   */
  name = "";

  constructor(data?: PartialMessage<GetJobRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.ml.v1beta1.GetJobRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): GetJobRequest {
    return new GetJobRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): GetJobRequest {
    return new GetJobRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): GetJobRequest {
    return new GetJobRequest().fromJsonString(jsonString, options);
  }

  static equals(a: GetJobRequest | PlainMessage<GetJobRequest> | undefined, b: GetJobRequest | PlainMessage<GetJobRequest> | undefined): boolean {
    return proto3.util.equals(GetJobRequest, a, b);
  }
}

/**
 * Request message for the CancelJob method.
 *
 * @generated from message google.cloud.ml.v1beta1.CancelJobRequest
 */
export class CancelJobRequest extends Message<CancelJobRequest> {
  /**
   * Required. The name of the job to cancel.
   *
   * Authorization: requires `Editor` role on the parent project.
   *
   * @generated from field: string name = 1;
   */
  name = "";

  constructor(data?: PartialMessage<CancelJobRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.ml.v1beta1.CancelJobRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): CancelJobRequest {
    return new CancelJobRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): CancelJobRequest {
    return new CancelJobRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): CancelJobRequest {
    return new CancelJobRequest().fromJsonString(jsonString, options);
  }

  static equals(a: CancelJobRequest | PlainMessage<CancelJobRequest> | undefined, b: CancelJobRequest | PlainMessage<CancelJobRequest> | undefined): boolean {
    return proto3.util.equals(CancelJobRequest, a, b);
  }
}

